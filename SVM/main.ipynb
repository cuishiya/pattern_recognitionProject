{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3dcf766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image 2412 cannot be reshaped to target size.\n",
      "Warning: Image 2416 cannot be reshaped to target size.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 创建保存图像的目标文件夹\n",
    "output_folder = 'image_data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 图片范围\n",
    "train_start = 1223\n",
    "train_end = 3222\n",
    "test_start = 3223\n",
    "test_end = 5222\n",
    "\n",
    "# 目标图像大小\n",
    "target_size = (128, 128)\n",
    "\n",
    "# 加载图像数据\n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "# 获取原始文件名列表\n",
    "train_filenames = [str(i) for i in range(train_start, train_end + 1) if os.path.exists(f'rawdata/{i}')]\n",
    "test_filenames = [str(i) for i in range(test_start, test_end + 1) if os.path.exists(f'rawdata/{i}')]\n",
    "\n",
    "for filename in train_filenames:\n",
    "    image_path = f'rawdata/{filename}'\n",
    "    try:\n",
    "        image = np.fromfile(image_path, dtype=np.uint8)\n",
    "        train_images.append(image)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Image {filename} not found.\")\n",
    "\n",
    "for filename in test_filenames:\n",
    "    image_path = f'rawdata/{filename}'\n",
    "    try:\n",
    "        image = np.fromfile(image_path, dtype=np.uint8)\n",
    "        test_images.append(image)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Image {filename} not found.\")\n",
    "\n",
    "# 转换并保存训练集图像\n",
    "for filename, image in zip(train_filenames, train_images):\n",
    "    try:\n",
    "        image = np.reshape(image, target_size)\n",
    "        img = Image.fromarray(image)\n",
    "        img.save(f'{output_folder}/{filename}.png')\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Image {filename} cannot be reshaped to target size.\")\n",
    "\n",
    "# 转换并保存测试集图像\n",
    "for filename, image in zip(test_filenames, test_images):\n",
    "    try:\n",
    "        image = np.reshape(image, target_size)\n",
    "        img = Image.fromarray(image)\n",
    "        img.save(f'{output_folder}/{filename}.png')\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Image {filename} cannot be reshaped to target size.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "638c7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('./image_data//1223.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "faces = detector(gray)\n",
    "\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "for face in faces:\n",
    "    landmarks = predictor(gray, face)\n",
    "    \n",
    "for n in range(0, 68):\n",
    "    x = landmarks.part(n).x\n",
    "    y = landmarks.part(n).y\n",
    "    cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "    \n",
    "cv2.imshow('Windows', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "525e5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "output_dir = './input_train//serious_tezheng'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "input_dir = './input_train//serious'\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # 读取图像文件\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        image = dlib.load_rgb_image(image_path)\n",
    "\n",
    "        # 使用人脸检测器检测人脸\n",
    "        dets = detector(image, 1)\n",
    "\n",
    "        # 创建带有特征信息的图片副本\n",
    "        img_with_features = Image.fromarray(image)\n",
    "        draw = ImageDraw.Draw(img_with_features)\n",
    "\n",
    "        # 遍历检测到的人脸\n",
    "        for i, det in enumerate(dets):\n",
    "            # 使用形状预测器获取人脸关键点\n",
    "            shape = predictor(image, det)\n",
    "\n",
    "            # 绘制人脸关键点\n",
    "            for pt in shape.parts():\n",
    "                draw.point((pt.x, pt.y), fill=(255, 0, 0))  # 红色标记关键点\n",
    "\n",
    "            # 保存带有特征信息的图片\n",
    "            output_image_path = os.path.join(output_dir, f'{filename}_face{i}.jpg')\n",
    "            img_with_features.save(output_image_path)\n",
    "\n",
    "            # 保存特征信息到文本文件\n",
    "            face_features_path = os.path.join(output_dir, f'{filename}_face{i}.txt')\n",
    "            with open(face_features_path, 'w') as f:\n",
    "                for pt in shape.parts():\n",
    "                    f.write(f'{pt.x} {pt.y}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb42b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件分类完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# 设置文件夹路径和标签文件路径\n",
    "folder_path = \"./image_test\"\n",
    "label_file_path = \"./data_label//test_label.npy\"\n",
    "\n",
    "# 读取标签文件\n",
    "labels = np.load(label_file_path)\n",
    "\n",
    "# 创建目标文件夹\n",
    "output_folder = \"output_test\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 根据标签分类文件\n",
    "for label in np.unique(labels[:, 1]):\n",
    "    label_folder = os.path.join(output_folder, label)\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "    indices = np.where(labels[:, 1] == label)[0]\n",
    "    for index in indices:\n",
    "        file_name = labels[index, 0] + \".png\"\n",
    "        source_path = os.path.join(folder_path, file_name)\n",
    "        destination_path = os.path.join(label_folder, file_name)\n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "print(\"文件分类完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae6fc3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#生成68个点对应灰度值文件\n",
    "import dlib\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "output_dir = './all_features'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "input_dir = './all_features//smiling'\n",
    "\n",
    "# 创建一个空的列表来保存所有特征点像素值\n",
    "all_features = []\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # 读取图像文件\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # 将图像转换为灰度图像\n",
    "        image_gray = image.convert('L')\n",
    "\n",
    "        # 将灰度图像转换为numpy数组\n",
    "        image_array = np.array(image_gray)\n",
    "\n",
    "        # 使用人脸检测器检测人脸\n",
    "        dets = detector(image_array, 1)\n",
    "\n",
    "        # 遍历检测到的人脸\n",
    "        for i, det in enumerate(dets):\n",
    "            # 使用形状预测器获取人脸关键点\n",
    "            shape = predictor(image_array, det)\n",
    "\n",
    "            # 创建一个空的列表来保存当前人脸的特征点像素值\n",
    "            face_features = []\n",
    "            \n",
    "            # 遍历人脸关键点\n",
    "            for pt in shape.parts():\n",
    "                # 确保像素值的索引不超过图像数组的大小\n",
    "                x = min(max(pt.x - 1, 0), image_array.shape[1] - 1)\n",
    "                y = min(max(pt.y - 1, 0), image_array.shape[0] - 1)\n",
    "\n",
    "                # 获取特征点的像素值（灰度值），并添加到列表中\n",
    "                pixel_value = image_array[y, x]\n",
    "                face_features.append(pixel_value)\n",
    "\n",
    "            ## 遍历人脸关键点\n",
    "            #for pt in shape.parts():\n",
    "                ## 获取特征点的像素值（灰度值），并添加到列表中\n",
    "               # pixel_value = image_array[pt.y, pt.x]\n",
    "               # face_features.append(pixel_value)\n",
    "\n",
    "            # 将当前人脸的特征点像素值添加到总体特征列表中\n",
    "            all_features.append(face_features)\n",
    "\n",
    "# 将所有特征点像素值转换为NumPy数组\n",
    "all_features_array = np.array(all_features)\n",
    "\n",
    "# 保存特征点像素值数组到.npy文件\n",
    "output_npy_path = os.path.join(output_dir, 'all_smiling_features.npy')\n",
    "np.save(output_npy_path, all_features_array)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "147fd0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   4  22 ...  98 108 120]\n",
      " [ 33  14  17 ...  59  89 103]\n",
      " [  4  33  12 ... 113 106 118]\n",
      " ...\n",
      " [  0   0   0 ... 116 107 123]\n",
      " [  0   0  26 ...  55  55  68]\n",
      " [ 14  19   8 ...  73 102 107]]\n"
     ]
    }
   ],
   "source": [
    "#打印npy\n",
    "import numpy as np\n",
    "\n",
    "# 读取.npy文件并禁用内存映射\n",
    "data = np.load('./all_features//all_smiling_features.npy')\n",
    "\n",
    "# 打印数据\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "607c3e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#生成excel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 读取.npy文件\n",
    "data = np.load('./all_features//all_smiling_features.npy')\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存为 Excel 文件\n",
    "df.to_excel('./all_features//all_smiling_features.xlsx', index=False)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34fe6915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练准确率: 0.7923799006073993\n"
     ]
    }
   ],
   "source": [
    "#将生成的文件导入SVM进行训练\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载特征文件\n",
    "funny_features = np.load('./input_train//funny_tezheng//funny_features.npy')\n",
    "serious_features = np.load('./input_train//serious_tezheng//serious_features.npy')\n",
    "smiling_features = np.load('./input_train//smiling_tezheng//smiling_features.npy')\n",
    "\n",
    "# 创建标签，假设每个特征文件中的数据都对应于一定的类别（例如，funny、serious、smiling）\n",
    "funny_labels = np.zeros(funny_features.shape[0])  # 使用0表示funny类别\n",
    "serious_labels = np.ones(serious_features.shape[0])  # 使用1表示serious类别\n",
    "smiling_labels = np.full(smiling_features.shape[0], 2)  # 使用2表示smiling类别\n",
    "\n",
    "# 组合特征和标签\n",
    "X = np.concatenate((funny_features, serious_features, smiling_features), axis=0)\n",
    "y = np.concatenate((funny_labels, serious_labels, smiling_labels))\n",
    "\n",
    "# 创建SVM分类器并进行训练\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# 打印训练结果\n",
    "print(\"训练准确率:\", classifier.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71733bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类准确率： 0.6340314136125654\n"
     ]
    }
   ],
   "source": [
    "#结合训练集和测试集进行预测\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载训练数据\n",
    "funny_features = np.load('./input_train//funny_tezheng//funny_features.npy')\n",
    "serious_features = np.load('./input_train//serious_tezheng//serious_features.npy')\n",
    "smiling_features = np.load('./input_train//smiling_tezheng//smiling_features.npy')\n",
    "\n",
    "# 创建训练数据集\n",
    "X_train = np.vstack((funny_features, serious_features, smiling_features))\n",
    "# 创建标签，其中funny特征对应标签0，serious特征对应标签1，smiling特征对应标签2\n",
    "y_train = np.hstack((np.zeros(len(funny_features)), np.ones(len(serious_features)), 2*np.ones(len(smiling_features))))\n",
    "\n",
    "# 创建SVM分类器\n",
    "classifier = svm.SVC()\n",
    "\n",
    "# 训练分类器\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 加载测试数据\n",
    "test_funny_features =np.load('./input_test//funny_tezheng//funny_features.npy')\n",
    "test_serious_features = np.load('./input_test//serious_tezheng//serious_features.npy')\n",
    "test_smiling_features =np.load('./input_test//smiling_tezheng//smiling_features.npy')\n",
    "\n",
    "# 创建测试数据集\n",
    "X_test = np.vstack((test_funny_features, test_serious_features, test_smiling_features))\n",
    "# 创建测试标签\n",
    "y_test = np.hstack((np.zeros(len(test_funny_features)), np.ones(len(test_serious_features)), 2*np.ones(len(test_smiling_features))))\n",
    "\n",
    "# 进行预测\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# 计算分类性能\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"分类准确率：\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52220c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "扩增后的funny特征样本数量： 1824\n",
      "交叉验证准确率： 0.819976411319197\n",
      "混淆矩阵：\n",
      "[[368  15   9]\n",
      " [  3 278  53]\n",
      " [  1  96 267]]\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.96       392\n",
      "         1.0       0.71      0.83      0.77       334\n",
      "         2.0       0.81      0.73      0.77       364\n",
      "\n",
      "    accuracy                           0.84      1090\n",
      "   macro avg       0.84      0.83      0.83      1090\n",
      "weighted avg       0.85      0.84      0.84      1090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#利用总的数据进行交叉验证 with SVM\n",
    "import numpy as np\n",
    "import imgaug.augmenters as iaa\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载训练数据\n",
    "funny_features = np.load('./all_features//all_funny_features.npy')\n",
    "serious_features = np.load('./all_features//all_serious_features.npy')\n",
    "smiling_features = np.load('./all_features//all_smiling_features.npy')\n",
    "\n",
    "\n",
    "# 定义图像增强器，扩增样本\n",
    "augmenter = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),       # 水平翻转\n",
    "    iaa.Affine(rotate=(-10, 10)),   # 旋转角度范围为-10度到10度\n",
    "    iaa.Affine(scale=(0.8, 1.2)),    # 缩放比例范围为0.8到1.2\n",
    "        iaa.Affine(translate_px={\"x\": (-10, 10), \"y\": (-10, 10)})  # 水平和垂直平移范围为-10到10个像素\n",
    "])\n",
    "\n",
    "# 扩增funny特征的数据\n",
    "augmented_features = [funny_features]\n",
    "num_augmentations = 18  # 扩增x次\n",
    "\n",
    "for _ in range(num_augmentations):\n",
    "    augmented = augmenter.augment_images(funny_features)\n",
    "    augmented_features.append(augmented)\n",
    "\n",
    "# 合并所有扩增后的数据\n",
    "augmented_funny_features = np.vstack(augmented_features)\n",
    "\n",
    "# 创建标签，其中原始funny特征对应标签0，扩增后的funny特征对应标签0\n",
    "y_train_funny = np.hstack((np.zeros(len(funny_features)), np.zeros(len(augmented_funny_features) - len(funny_features))))\n",
    "\n",
    "# 打印扩增后的数据数量\n",
    "print(\"扩增后的funny特征样本数量：\", len(augmented_funny_features))\n",
    "\n",
    "# 将扩增后的数据与其他特征数据合并\n",
    "X_train = np.vstack((augmented_funny_features, serious_features, smiling_features))\n",
    "y_train = np.hstack((y_train_funny, np.ones(len(serious_features)), 2 * np.ones(len(smiling_features))))\n",
    "\n",
    "# 创建SVM分类器并进行训练\n",
    "classifier = svm.SVC()\n",
    "#classifier.fit(X_train, y_train)\n",
    "\n",
    "# 执行交叉验证并计算分类准确率\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)  # 将数据分为5个折叠进行交叉验证\n",
    "mean_accuracy = np.mean(scores)\n",
    "\n",
    "print(\"交叉验证准确率：\", mean_accuracy)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"混淆矩阵：\")\n",
    "print(confusion)\n",
    "\n",
    "# 打印分类报告\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"分类报告：\")\n",
    "print(report)\n"
   ]
  }